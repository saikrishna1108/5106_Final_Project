{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdeaa02-1ca9-4433-b9f7-d18a685e8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "class SpeedDataset(Dataset):\n",
    "    def __init__(self, directory, sequence_length=5):\n",
    "        self.data = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_speed = 0  # Variable to store the maximum speed found\n",
    "        self.preprocess_data(directory)\n",
    "        # Calculate number of classes based on the range from 30 to 105\n",
    "        self.num_classes = (105 - 30) // 10 + 1  # From class 30-39, ..., 100-105\n",
    "\n",
    "    def preprocess_data(self, directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.txt'):\n",
    "                speed = float(filename.split('_')[-1].replace('.txt', ''))\n",
    "                # Update maximum speed if current speed is greater\n",
    "                if speed > self.max_speed:\n",
    "                    self.max_speed = speed\n",
    "                # Convert speed to class, starting range from 30\n",
    "                if speed < 30:\n",
    "                    speed_class = 0  # Handle speeds below 30 as class 0\n",
    "                else:\n",
    "                    speed_class = (int(speed) - 30) // 10\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                with open(filepath, 'r') as file:\n",
    "                    track_data = {}\n",
    "                    for line in file:\n",
    "                        frame, track_id, x1, y1, x2, y2 = map(float, line.strip().split(',')[:6])\n",
    "                        if track_id not in track_data:\n",
    "                            track_data[track_id] = []\n",
    "                        track_data[track_id].append([x1,y1,x2,y2,(x1+x2)/2, (y1+y2)/2])\n",
    "\n",
    "                    for track_id, frames in track_data.items():\n",
    "                        if len(frames) >= self.sequence_length:\n",
    "                            features = []\n",
    "                            for i in range(1, len(frames)):\n",
    "                                current_frame = frames[i]\n",
    "                                previous_frame = frames[i-1]\n",
    "                                data_d = []\n",
    "                                for i in range(4):\n",
    "                                    data_d.append(current_frame[i])\n",
    "                                for j in range(4,6):\n",
    "                                    data_d.append(current_frame[j] - previous_frame[j])\n",
    "                                features.append(data_d)\n",
    "                                \n",
    "                            for i in range(len(features) - self.sequence_length + 1):\n",
    "                                sequence = features[i:i + self.sequence_length]\n",
    "                                self.data.append((sequence, speed_class))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs, output = self.data[idx]\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(output, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef913e89-0e2a-41b1-9e5f-1fe38c041bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpeedDataset('outputs', sequence_length=5)\n",
    "test_dataset = SpeedDataset('test', sequence_length=5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec196b8-f2a3-4839-aa71-51eff2c137e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.0654e+02,  4.6902e+02,  6.6354e+02,  5.1220e+02,  1.3805e+00,\n",
       "           3.0359e-01],\n",
       "         [ 6.0735e+02,  4.7290e+02,  6.6468e+02,  5.1298e+02,  9.7501e-01,\n",
       "           2.3286e+00],\n",
       "         [ 6.0807e+02,  4.7742e+02,  6.6695e+02,  5.1390e+02,  1.4925e+00,\n",
       "           2.7197e+00],\n",
       "         [ 6.1008e+02,  4.7632e+02,  6.6941e+02,  5.1447e+02,  2.2345e+00,\n",
       "          -2.6654e-01],\n",
       "         [ 6.1158e+02,  4.7196e+02,  6.7179e+02,  5.1450e+02,  1.9440e+00,\n",
       "          -2.1621e+00]]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
