{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450b68b7-329c-4a25-92cf-9dd033b1e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import math\n",
    "class SpeedDataset(Dataset):\n",
    "    def __init__(self, directory, sequence_length=5):\n",
    "        self.data = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_speed = 0  # Variable to store the maximum speed found\n",
    "        self.preprocess_data(directory)\n",
    "        # Calculate number of classes based on the range from 30 to 105\n",
    "        self.num_classes = (105 - 30) // 3 +1   # From class 30-39, ..., 100-105\n",
    "\n",
    "    def preprocess_data(self, directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.txt'):\n",
    "                speed = float(filename.split('_')[-1].replace('.txt', ''))\n",
    "                # Update maximum speed if current speed is greater\n",
    "                if speed > self.max_speed:\n",
    "                    self.max_speed = speed\n",
    "                # Convert speed to class, starting range from 30\n",
    "                if speed < 30:\n",
    "                    speed_class = 0  # Handle speeds below 30 as class 0\n",
    "                else:\n",
    "                    speed_class = (int(speed) - 30) // 3\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                with open(filepath, 'r') as file:\n",
    "                    track_data = {}\n",
    "                    for line in file:\n",
    "                        frame, track_id, x1, y1, x2, y2 = map(float, line.strip().split(',')[:6])\n",
    "                        if track_id not in track_data:\n",
    "                            track_data[track_id] = []\n",
    "                        track_data[track_id].append([x1,y1,x2,y2,(x1+x2)/2, (y1+y2)/2])\n",
    "\n",
    "                    for track_id, frames in track_data.items():\n",
    "                        if len(frames) >= self.sequence_length:\n",
    "                            features = []\n",
    "                            for i in range(1, len(frames)):\n",
    "                                current_frame = frames[i]\n",
    "                                previous_frame = frames[i-1]\n",
    "                                data_d = []\n",
    "                                distance = 0\n",
    "                                distance1 = 0\n",
    "                                distance2 = 0\n",
    "                                for i in range(4):\n",
    "                                    data_d.append(abs(current_frame[i] - previous_frame[i]))\n",
    "                                for j in range(4,6):\n",
    "                                    distance = ((current_frame[j] - previous_frame[j])**2) + distance\n",
    "                                for j in range(0,2):\n",
    "                                    distance1 = ((current_frame[j] - previous_frame[j])**2) + distance1\n",
    "                                for j in range(2,4):\n",
    "                                    distance2 = ((current_frame[j] - previous_frame[j])**2) + distance2\n",
    "                                data_d.append(math.sqrt(distance))\n",
    "                                data_d.append(math.sqrt(distance1))\n",
    "                                data_d.append(math.sqrt(distance2))\n",
    "                                features.append(data_d)\n",
    "                            for i in range(len(features) - self.sequence_length + 1):\n",
    "                                sequence = features[i:i + self.sequence_length]\n",
    "                                self.data.append((sequence, speed_class))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs, output = self.data[idx]\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(output, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8245562-d2e4-4b96-b02d-1f8e325d625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpeedPredictor(nn.Module):\n",
    "    def __init__(self, sequence_length, feature_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(SpeedPredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=feature_size, out_channels=embedding_dim, kernel_size=1)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers = 3)\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_dim, out_channels=64, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Use only the last output of LSTM for further processing\n",
    "        x = x.unsqueeze(2)  # Adjust dimensions for the second conv layer\n",
    "        x = self.conv2(x)\n",
    "        x = x.squeeze(2)  # Flatten the output for FC layers\n",
    "        return self.relu(self.fc2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aa6932f-cadb-40ca-9f17-a69866cca6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e9374e2-b8f8-4c42-bf2b-7b02698f7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        Train_total_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Ensure inputs and targets are on the same device as model\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()  # First, update the parameters with the current learning rate\n",
    "            \n",
    "            Train_total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_train += (predicted == targets).sum().item()\n",
    "            total_train += targets.size(0)\n",
    "        \n",
    "        scheduler.step()  # After optimizer updates, adjust the learning rate\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            model.eval()\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in test_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    correct_test += (predicted == targets).sum().item()\n",
    "                    total_test += targets.size(0)\n",
    "                    \n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            test_accuracy = 100 * correct_test / total_test\n",
    "            print(f'Epoch {epoch+1}: Train Loss: {Train_total_loss / len(train_loader)} Test Loss: {total_loss / len(train_loader)}, '\n",
    "                  f'Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df1be032-2699-4e69-a658-cd9dfba41086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.2249886579811573 Test Loss: 2.570681574443976, Train Accuracy: 7.96%, Test Accuracy: 7.30%\n",
      "Epoch 11: Train Loss: 3.158883972093463 Test Loss: 2.522117213656505, Train Accuracy: 8.67%, Test Accuracy: 7.23%\n",
      "Epoch 21: Train Loss: 2.9371685249110064 Test Loss: 2.3359206207096577, Train Accuracy: 14.32%, Test Accuracy: 14.69%\n",
      "Epoch 31: Train Loss: 2.772980614875754 Test Loss: 2.250648913284143, Train Accuracy: 17.87%, Test Accuracy: 18.24%\n",
      "Epoch 41: Train Loss: 2.4545047596717873 Test Loss: 1.9836120791733265, Train Accuracy: 22.00%, Test Accuracy: 20.39%\n",
      "Epoch 51: Train Loss: 2.0005857444678745 Test Loss: 1.6165257301181555, Train Accuracy: 33.46%, Test Accuracy: 31.95%\n",
      "Epoch 61: Train Loss: 1.1288056566069524 Test Loss: 0.9118331841503581, Train Accuracy: 62.97%, Test Accuracy: 61.53%\n",
      "Epoch 71: Train Loss: 0.41643976043754566 Test Loss: 0.36834509910841007, Train Accuracy: 87.39%, Test Accuracy: 85.18%\n",
      "Epoch 81: Train Loss: 0.1927089344947793 Test Loss: 0.1469205134975103, Train Accuracy: 94.20%, Test Accuracy: 94.59%\n",
      "Epoch 91: Train Loss: 0.10045949223543478 Test Loss: 0.16973651378551344, Train Accuracy: 97.44%, Test Accuracy: 93.39%\n",
      "Epoch 101: Train Loss: 0.016405905812158988 Test Loss: 0.029756746954414364, Train Accuracy: 99.72%, Test Accuracy: 99.15%\n",
      "Epoch 111: Train Loss: 0.001954693012066855 Test Loss: 0.016262854219727767, Train Accuracy: 100.00%, Test Accuracy: 99.45%\n",
      "Epoch 121: Train Loss: 0.0012271607373198397 Test Loss: 0.016007404938856478, Train Accuracy: 100.00%, Test Accuracy: 99.41%\n",
      "Epoch 131: Train Loss: 0.0009245281349118765 Test Loss: 0.01605222587412906, Train Accuracy: 100.00%, Test Accuracy: 99.41%\n",
      "Epoch 141: Train Loss: 0.0007601467466808268 Test Loss: 0.016077816012815067, Train Accuracy: 100.00%, Test Accuracy: 99.41%\n",
      "Epoch 150: Train Loss: 0.0006622317001377572 Test Loss: 0.016101658667707852, Train Accuracy: 100.00%, Test Accuracy: 99.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# Assuming your SpeedPredictor and SpeedDataset are already defined and imported\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = SpeedDataset('outputs', sequence_length=25)\n",
    "test_size = int(0.20 * len(train_dataset))  # 10% for testing\n",
    "train_size = len(train_dataset) - test_size  # 90% for training\n",
    "\n",
    "# Split the dataset\n",
    "train_subset, test_subset = random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Model setup\n",
    "max_classes = train_dataset.num_classes\n",
    "model = SpeedPredictor(sequence_length=25, feature_size=7, embedding_dim=64, hidden_dim=128, output_size=max_classes)\n",
    "model.to(device)  # Ensure model is on the appropriate device\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Ensure loss function is on the appropriate device\n",
    "optimizer = SGD(model.parameters(), lr=0.05)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)  # Learning rate scheduler\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e683629-d384-4fa2-9133-59db1efceb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15353\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14bb4e32-9e8d-4179-9224-6c65ca79665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix_and_report(all_targets, all_preds):\n",
    "    print(confusion_matrix(all_targets, all_preds))\n",
    "    print(classification_report(all_targets, all_preds, target_names=[f'Class {30 + i * 3}-{33 + i * 3}' for i in range(max(all_targets) + 1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7bb827a-1680-4e24-96b0-6cca8631c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Classification Report:\n",
      "[[186   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0 224   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0 127   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1   0   0 193   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 134   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 248   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1   1   0   0   0   0 160   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 122   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 162   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0 164   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0 128   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0 136   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   2  96   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0 114   0   1   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0  74\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   73   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  70   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 106   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  50   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0  75   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0  52   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0  21]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Class 30-33       0.99      1.00      0.99       186\n",
      "  Class 33-36       1.00      1.00      1.00       224\n",
      "  Class 36-39       1.00      1.00      1.00       127\n",
      "  Class 39-42       1.00      0.99      1.00       194\n",
      "  Class 42-45       1.00      1.00      1.00       134\n",
      "  Class 45-48       1.00      1.00      1.00       249\n",
      "  Class 48-51       0.99      0.98      0.98       163\n",
      "  Class 51-54       1.00      1.00      1.00       122\n",
      "  Class 54-57       1.00      0.99      1.00       163\n",
      "  Class 57-60       1.00      1.00      1.00       108\n",
      "  Class 60-63       0.98      0.99      0.99       165\n",
      "  Class 63-66       0.98      0.99      0.99       129\n",
      "  Class 66-69       0.97      0.99      0.98       137\n",
      "  Class 69-72       0.99      0.97      0.98        99\n",
      "  Class 72-75       1.00      0.97      0.98       118\n",
      "  Class 75-78       1.00      1.00      1.00        82\n",
      "  Class 78-81       0.99      1.00      0.99        83\n",
      "  Class 81-84       0.99      0.99      0.99        75\n",
      "  Class 84-87       1.00      1.00      1.00        73\n",
      "  Class 87-90       1.00      1.00      1.00        70\n",
      "  Class 90-93       1.00      1.00      1.00       106\n",
      "  Class 93-96       1.00      1.00      1.00        64\n",
      "  Class 96-99       1.00      1.00      1.00        50\n",
      " Class 99-102       1.00      0.99      0.99        76\n",
      "Class 102-105       1.00      1.00      1.00        52\n",
      "Class 105-108       0.95      1.00      0.98        21\n",
      "\n",
      "     accuracy                           0.99      3070\n",
      "    macro avg       0.99      0.99      0.99      3070\n",
      " weighted avg       0.99      0.99      0.99      3070\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.41368078175896"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Ensure inputs and targets are on the same device as model\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_test += (predicted == targets).sum().item()\n",
    "            total_test += targets.size(0)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    print(\"Confusion Matrix and Classification Report:\")\n",
    "    print_confusion_matrix_and_report(all_targets, all_preds)\n",
    "    return test_accuracy\n",
    "evaluate(model, test_loader)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
