{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff2fe32-9778-407b-a3d6-43b0a1366403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "\n",
    "class SpeedDataset(Dataset):\n",
    "    def __init__(self, directory, sequence_length=5, augment=False, overlap=1):\n",
    "        self.data = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.augment = augment  # Enable or disable augmentation\n",
    "        self.overlap = overlap  # Control the overlap between sequences\n",
    "        self.preprocess_data(directory)\n",
    "\n",
    "    def preprocess_data(self, directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                df.sort_values(by=['id', 'frame'], inplace=True)  # Sort by track ID and frame number\n",
    "                \n",
    "                track_data = df.groupby('id')\n",
    "                \n",
    "                for track_id, group in track_data:\n",
    "                    group = group.reset_index(drop=True)  # Reset index after sorting\n",
    "                    for i in range(0, len(group) - self.sequence_length + 1, self.overlap):\n",
    "                        # Check if the frames within the window are consecutive\n",
    "                        if group['frame'].iloc[i:i + self.sequence_length].diff().dropna().eq(1).all():\n",
    "                            frames = group.iloc[i:i + self.sequence_length]\n",
    "                            features = self.extract_features(frames[['x_tl_2d', 'y_tl_2d', 'x_br_2d', 'y_br_2d']].values)\n",
    "                            speed = frames['average_speed_5_frames'].mean()  # Calculate the average speed for the sequence\n",
    "                            self.data.append((features, speed))\n",
    "\n",
    "    def extract_features(self, frames):\n",
    "        features = []\n",
    "        for i in range(1, len(frames)):\n",
    "            current_frame = frames[i]\n",
    "            previous_frame = frames[i-1]\n",
    "            features.append(self.compute_frame_features(current_frame, previous_frame))\n",
    "        return features\n",
    "\n",
    "    def compute_frame_features(self, current_frame, previous_frame):\n",
    "        x1, y1, x2, y2 = current_frame\n",
    "        px1, py1, px2, py2 = previous_frame\n",
    "        \n",
    "        x1_change = abs(x1 - px1)\n",
    "        y1_change = abs(y1 - py1)\n",
    "        x2_change = abs(x2 - px2)\n",
    "        y2_change = abs(y2 - py2)\n",
    "\n",
    "        center_x_change = abs((x1 + x2)/2 - (px1 + px2)/2)\n",
    "        center_y_change = abs((y1 + y2)/2 - (py1 + py2)/2)\n",
    "        distance_moved1 = math.sqrt(center_x_change ** 2 + center_y_change ** 2)\n",
    "        distance_moved2 = math.sqrt(x1_change ** 2 + y1_change ** 2)\n",
    "        distance_moved3 = math.sqrt(x2_change ** 2 + y2_change ** 2)\n",
    "\n",
    "        feature_vector = [distance_moved1, distance_moved2, distance_moved3, center_x_change, center_y_change, x1_change, y1_change, x2_change, y2_change]\n",
    "        return feature_vector\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs, output = self.data[idx]\n",
    "        if self.augment:\n",
    "            inputs = self.apply_augmentation(inputs)\n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(output, dtype=torch.float32)\n",
    "\n",
    "    def apply_augmentation(self, inputs):\n",
    "        if random.random() > 0.6:\n",
    "            inputs = self.add_noise(inputs)\n",
    "        if random.random() > 0.99:\n",
    "            inputs = self.time_shift(inputs, shift=random.choice([-1, 1]))\n",
    "        if random.random() > 0.8:\n",
    "            inputs = self.scale_features(inputs, scale=random.uniform(0.9, 1.1))\n",
    "        if random.random() > 0.99:\n",
    "            inputs = self.mirror_features(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def add_noise(self, features, noise_level=0.05):\n",
    "        noise = np.random.normal(0, noise_level, features.shape)\n",
    "        return features + noise\n",
    "\n",
    "    def time_shift(self, features, shift=1):\n",
    "        if shift > 0:\n",
    "            return np.vstack([np.zeros((shift, features.shape[1])), features[:-shift]])\n",
    "        elif shift < 0:\n",
    "            return np.vstack([features[-shift:], np.zeros((-shift, features.shape[1]))])\n",
    "        return features\n",
    "\n",
    "    def scale_features(self, features, scale=1.1):\n",
    "        return features * scale\n",
    "\n",
    "    def mirror_features(self, features):\n",
    "        features_copy = features.copy()\n",
    "        features_copy[:, [0, 2]] = -features_copy[:, [0, 2]]  # Assume these indices are the x-coordinates\n",
    "        return features_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5790898d-4519-462e-a38c-b76b6916615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310559572644723\n"
     ]
    }
   ],
   "source": [
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3841e3-dbc1-44e3-bafe-a354d368d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41c456a-1d9e-4868-9770-da006347ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.attention(x).squeeze(2) \n",
    "        alpha = F.softmax(scores, dim=1).unsqueeze(2)  \n",
    "        context = (x * alpha).sum(dim=1)\n",
    "        return context, alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1009e48-d61c-4e61-b3fa-0b1e75737109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeedPredictor(nn.Module):\n",
    "    def __init__(self, sequence_length, feature_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(SpeedPredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=feature_size, out_channels=hidden_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=embedding_dim, out_channels=hidden_dim, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.lstm = nn.RNN(hidden_dim, hidden_dim, batch_first=True, num_layers=4, dropout=0.2)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.conv3 = nn.Conv1d(in_channels=hidden_dim, out_channels=64, kernel_size=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.conv1(x)\n",
    "        #x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x, _ = self.lstm(x)\n",
    "        x, attn_weights = self.attention(x)  \n",
    "        x = x.unsqueeze(2) \n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.squeeze(2)  \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.LSTM:\n",
    "        torch.nn.init.xavier_uniform_(m.weight_ih_l0)\n",
    "        torch.nn.init.orthogonal_(m.weight_hh_l0)\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc80739b-e924-40df-ba55-22801c0694a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer,scheduler, epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, speeds in train_loader:\n",
    "            inputs, speeds = inputs.to(device), speeds.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze() \n",
    "            if outputs.shape != speeds.shape:\n",
    "                outputs = outputs[:speeds.size(0)]  \n",
    "            loss = criterion(outputs, speeds)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, speeds in val_loader:\n",
    "                inputs, speeds= inputs.to(device), speeds.to(device)\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()  \n",
    "                if outputs.shape != speeds.shape:\n",
    "                    outputs = outputs[:speeds.size(0)]  \n",
    "                loss = torch.sqrt(criterion(outputs, speeds))\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        if epoch % 10 ==0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, MSE training Loss: {avg_train_loss:.4f}, RMSE validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8694675c-5004-42c4-9f4a-a15c8ab23d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25978"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "train_dataset = SpeedDataset('../train', sequence_length=10, overlap = 5, augment =False)\n",
    "test_dataset = SpeedDataset('../val', sequence_length=10, overlap = 5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf819d-6d2a-49fc-b3d7-7384353cb765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, MSE training Loss: 185.9566, RMSE validation Loss: 13.0377\n",
      "Epoch 11/200, MSE training Loss: 81.9152, RMSE validation Loss: 13.1224\n",
      "Epoch 21/200, MSE training Loss: 72.3270, RMSE validation Loss: 11.4317\n",
      "Epoch 31/200, MSE training Loss: 64.9158, RMSE validation Loss: 12.5526\n",
      "Epoch 41/200, MSE training Loss: 60.6061, RMSE validation Loss: 12.1434\n",
      "Epoch 51/200, MSE training Loss: 53.9000, RMSE validation Loss: 16.9436\n",
      "Epoch 61/200, MSE training Loss: 54.4160, RMSE validation Loss: 12.0690\n",
      "Epoch 71/200, MSE training Loss: 50.5677, RMSE validation Loss: 13.0393\n",
      "Epoch 81/200, MSE training Loss: 50.6932, RMSE validation Loss: 12.4523\n",
      "Epoch 91/200, MSE training Loss: 47.8990, RMSE validation Loss: 11.4289\n",
      "Epoch 101/200, MSE training Loss: 44.5041, RMSE validation Loss: 12.9546\n",
      "Epoch 111/200, MSE training Loss: 46.8019, RMSE validation Loss: 11.5754\n",
      "Epoch 121/200, MSE training Loss: 45.4636, RMSE validation Loss: 11.5386\n",
      "Epoch 131/200, MSE training Loss: 45.4708, RMSE validation Loss: 12.3703\n",
      "Epoch 141/200, MSE training Loss: 41.6776, RMSE validation Loss: 12.2851\n",
      "Epoch 151/200, MSE training Loss: 41.4355, RMSE validation Loss: 12.5403\n",
      "Epoch 161/200, MSE training Loss: 43.1116, RMSE validation Loss: 10.6557\n",
      "Epoch 171/200, MSE training Loss: 40.4513, RMSE validation Loss: 15.2265\n",
      "Epoch 181/200, MSE training Loss: 40.8040, RMSE validation Loss: 13.4071\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss, and Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SpeedPredictor(sequence_length=10, feature_size=9, embedding_dim=64, hidden_dim=128, output_size=1)\n",
    "model.to(device)\n",
    "model.apply(init_weights)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Scheduler for learning rate adjustment\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9992)\n",
    "train_losses,val_losses = train_and_validate(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf60c9-2d45-4d60-8746-ba9821d26043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 200+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, 200+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('RNN Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6738b-bd77-4461-9076-0b8a171e17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 200+1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('RNN Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5642f79-1481-4468-96cf-1028deeed46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "def predict_and_compare(model, test_loader, criterion, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view_as(targets)  # Ensure outputs and targets have the same shape\n",
    "            loss = torch.sqrt(criterion(outputs, targets))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            actuals.extend(targets.tolist())\n",
    "\n",
    "    return predictions, actuals, total_loss / len(test_loader)\n",
    "\n",
    "def calculate_accuracy(predictions, actuals):\n",
    "    accuracies = []\n",
    "    for pred, actual in zip(predictions, actuals):\n",
    "        if actual != 0:\n",
    "            accuracy = (1 - abs(pred - actual) / abs(actual)) * 100\n",
    "        else:\n",
    "            accuracy = 0  # Decide how to handle actual == 0; perhaps continue or set a default accuracy value\n",
    "        accuracies.append(accuracy)\n",
    "    return sum(accuracies) / len(accuracies) if accuracies else 0\n",
    "\n",
    "\n",
    "\n",
    "def print_random_predictions(predictions, actuals, num_samples=30):\n",
    "    if len(predictions) < num_samples:\n",
    "        num_samples = len(predictions)  # Adjust sample size if predictions are fewer than requested\n",
    "\n",
    "    # Get random sample indices\n",
    "    sample_indices = random.sample(range(len(predictions)), num_samples)\n",
    "\n",
    "    # Print the randomly selected predictions and their actual values\n",
    "    for idx in sample_indices:\n",
    "        print(f\"Predicted: {predictions[idx]:.4f}, Actual: {actuals[idx]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = SpeedDataset('../test', sequence_length=10, overlap = 5)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "predictions, actuals, loss = predict_and_compare(model, test_loader, criterion, device)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = calculate_accuracy(predictions, actuals)\n",
    "print(f\"Average Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Final RMSE Loss: {loss:.4f}\")\n",
    "print_random_predictions(predictions, actuals, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e82c5-d425-43f7-9a4f-1bf47cb9903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a plot with both predictions and actuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plotting actual speeds\n",
    "plt.plot(actuals, label='Actual Speed', color='blue', marker='o', linestyle='', markersize=5)\n",
    "\n",
    "# Plotting predicted speeds\n",
    "plt.plot(predictions, label='Predicted Speed', color='red', marker='x', linestyle='', markersize=5)\n",
    "\n",
    "plt.title('Comparison of Actual and Predicted Speeds')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Speed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to visualize the correlation between actual and predicted speeds\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(actuals, predictions, color='green')\n",
    "plt.title('Actual vs Predicted Speeds')\n",
    "plt.xlabel('Actual Speed')\n",
    "plt.ylabel('Predicted Speed')\n",
    "plt.grid(True)\n",
    "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'k--')  # Diagonal line for reference\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44483e31-7209-421f-9d20-0662d78ad4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(actuals, predictions, color='green', alpha=0.5)  # Adjust transparency with alpha\n",
    "plt.title('Actual vs Predicted Speeds')\n",
    "plt.xlabel('Actual Speed')\n",
    "plt.ylabel('Predicted Speed')\n",
    "plt.grid(True)\n",
    "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'k--')  # Diagonal line for reference\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
